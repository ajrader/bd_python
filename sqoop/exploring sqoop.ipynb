{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook to illustrate using the sqoop command from within the IPython Notebook\n",
    "Need to define the password file where I've stored the password for my access to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable        Type       Data/Info\n",
      "------------------------------------\n",
      "dbList          list       n=438\n",
      "dbip            str        jdbc:db2://10.96.37.164:60100/FDW2P\n",
      "lVNDRCDS        ndarray    20: 20 elems, type `|S8`, 160 bytes\n",
      "listOfVNDRCDS   ndarray    21: 21 elems, type `|S8`, 168 bytes\n",
      "nDETLlines      dict       n=20\n",
      "nfile           str        /user/kesj/config/e.pswd\n",
      "tblList         list       n=17099\n",
      "tgt             str        vrp/Y1753AAA_DETL\n",
      "user            str        kesj\n",
      "vcd             str        910848\n",
      "vndrCd          str        Y1753AAA\n",
      "wclause         str        \"LOS_EST_DIM_ID IN ( SELE<...>VNDR_VEH_CD='Y1753AAA' )\"\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nfile = '/user/kesj/config/e.pswd'\n",
    "#alternatively can use relative path: nfile = 'config/e.pswd'\n",
    "# to use local File space you must prefice the file name with file:\n",
    "user = 'kesj'\n",
    "dbip = 'jdbc:db2://10.96.37.166:60100/FDW2P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!sqoop list-tables --connect jdbc:db2://10.96.37.164:60100/FDW2P --username kesj --password-file '/user/kesj/config/e.pswd'\n",
    "#!sqoop list-tables --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password {myPSWD}\n",
    "#!sqoop list-tables --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbList = !sqoop list-databases --connect jdbc:db2://10.96.37.166:60100/FDW2P --username {user} --password-file {nfile}\n",
    "dbList=dbList[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 438 databases (schemas) within this DB\n"
     ]
    }
   ],
   "source": [
    "print \"There are {0} databases (schemas) within this DB\".format(len(dbList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17099 tables in these schemas.\n"
     ]
    }
   ],
   "source": [
    "tblList = !sqoop list-tables --connect jdbc:db2://10.96.37.166:60100/FDW2P --username {user} --password-file {nfile}\n",
    "tblList = tblList[5:]\n",
    "print \"There are {0} tables in these schemas.\".format(len(tblList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at bringing a particular table in Avro format, sequential pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8512' )\" --target-dir vrp_data/ARM8512_DETL --split-by DETL_DIM_ID --class-name \"sf.datascience.vrp.avro.export.DETL\" \n",
    "            #--splity-by DETL_DIM_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 15:12:30 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 15:12:31 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 15:12:31 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 15:12:32 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 15:12:32 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 15:12:32 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/e636ac2526ceb87f87ae0cdd568aad32/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 15:12:34 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/e636ac2526ceb87f87ae0cdd568aad32/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 15:12:34 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 15:12:34 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 15:12:35 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 15:12:35 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 15:12:35 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 15:12:37 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 15:12:37 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8512' ) )\n",
      "14/10/28 15:13:00 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 15:13:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0195\n",
      "14/10/28 15:13:01 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0195\n",
      "14/10/28 15:13:01 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0195/\n",
      "14/10/28 15:13:01 INFO mapreduce.Job: Running job: job_1412635903408_0195\n",
      "14/10/28 15:13:07 INFO mapreduce.Job: Job job_1412635903408_0195 running in uber mode : false\n",
      "14/10/28 15:13:07 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 15:13:22 INFO mapreduce.Job: Task Id : attempt_1412635903408_0195_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 126681\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 15:13:26 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 15:13:27 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 15:13:38 INFO mapreduce.Job: Task Id : attempt_1412635903408_0195_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 8495\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 15:13:54 INFO mapreduce.Job: Task Id : attempt_1412635903408_0195_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 291068\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 15:14:09 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 15:14:09 INFO mapreduce.Job: Job job_1412635903408_0195 failed with state FAILED due to: Task failed task_1412635903408_0195_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 15:14:09 INFO mapreduce.Job: Counters: 9\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=4\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=7\n",
      "\t\tOther local map tasks=7\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=237670\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=237670\n",
      "\t\tTotal vcore-seconds taken by all map tasks=237670\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=243374080\n",
      "14/10/28 15:14:09 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 15:14:09 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 94.755 seconds (0 bytes/sec)\n",
      "14/10/28 15:14:09 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead\n",
      "14/10/28 15:14:09 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 15:14:09 ERROR tool.ImportTool: Error during import: Import job failed!\n"
     ]
    }
   ],
   "source": [
    "!sqoop import -DDdb2.jcc.charsetDecoderEncoder=3 -DcharacterEncoding=UTF8 -Dlocale=us_en --username kesj --password-file {nfile} --connect jdbc:db2://10.96.37.166:60100/FDW2P -table FDWATOMCAE.DETL --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8512' )\" --target-dir vrp_data/ARM8512_DETL --split-by DETL_DIM_ID --class-name \"sf.datascience.vrp.avro.export.DETL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sqoop import  -DcharacterEncoding=utf8 --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8512' )\" --target-dir vrp_data/ARM8512_DETL -m 1 --class-name \"sf.datascience.vrp.avro.export.DETL\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listOfVNDRCDS = ['ARM8522', '', 'Y1753CAA', '910698', 'Y1753BAD', 'Y1753BAA',\n",
    "       'Y1753DAA', 'Y1753DAD', 'Y1753AAA', 'Y1753CAD', 'ARM8427',\n",
    "       'ARM8516', 'ARM8192', '911754', 'ARM8545', 'Y2114AER', 'ARM8512',\n",
    "       '910027', 'ARM8530', 'ARM8416', '910848']\n",
    "#for vcd in listOfVNDRCDS[3:]:\n",
    "#    print vcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 08:23:10 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 08:23:11 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 08:23:11 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 08:23:12 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:23:13 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:23:13 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/76b1af2bee7103b4fa4714bb6db896f9/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 08:23:15 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/76b1af2bee7103b4fa4714bb6db896f9/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 08:23:15 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 08:23:15 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 08:23:15 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:23:16 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:23:16 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:23:16 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/76b1af2bee7103b4fa4714bb6db896f9/DETL.avsc\n",
      "14/10/28 08:23:16 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 08:23:17 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 08:23:19 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 08:23:19 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "14/10/28 08:23:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0155\n",
      "14/10/28 08:23:19 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0155\n",
      "14/10/28 08:23:19 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0155/\n",
      "14/10/28 08:23:19 INFO mapreduce.Job: Running job: job_1412635903408_0155\n",
      "14/10/28 08:23:24 INFO mapreduce.Job: Job job_1412635903408_0155 running in uber mode : false\n",
      "14/10/28 08:23:24 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 08:23:44 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 08:24:23 INFO mapreduce.Job: Job job_1412635903408_0155 completed successfully\n",
      "14/10/28 08:24:23 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=109980\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=87\n",
      "\t\tHDFS: Number of bytes written=24101544\n",
      "\t\tHDFS: Number of read operations=4\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tOther local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=55597\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=55597\n",
      "\t\tTotal vcore-seconds taken by all map tasks=55597\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=56931328\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=83887\n",
      "\t\tMap output records=83887\n",
      "\t\tInput split bytes=87\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=145\n",
      "\t\tCPU time spent (ms)=12820\n",
      "\t\tPhysical memory (bytes) snapshot=338812928\n",
      "\t\tVirtual memory (bytes) snapshot=1582243840\n",
      "\t\tTotal committed heap usage (bytes)=737148928\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=24101544\n",
      "14/10/28 08:24:23 INFO mapreduce.ImportJobBase: Transferred 22.985 MB in 66.5142 seconds (353.8591 KB/sec)\n",
      "14/10/28 08:24:23 INFO mapreduce.ImportJobBase: Retrieved 83887 records.\n"
     ]
    }
   ],
   "source": [
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='Y1753DAA' )\" --target-dir vrp_data/Y1753DAA_DETL -m 1 --class-name \"sf.datascience.vrp.avro.export.DETL\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat, pulling in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 items\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-28 08:22 vrp_data/ARM8512_DETL\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 08:42 vrp_data/ARM8522_AUTO_EST_SUM\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 08:55 vrp_data/ARM8522_EST_PARTY_DETL_RLTN\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 08:57 vrp_data/ARM8522_LBR_NOTE\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 08:32 vrp_data/ARM8522_LOS_EST\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 09:21 vrp_data/ARM8522_MSG\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 09:39 vrp_data/ARM8522_OPT\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 10:27 vrp_data/ARM8522_RATE\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 10:49 vrp_data/ARM8522_TAX\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:37 vrp_data/P3533CGB_AUTO_EST_SUM\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:39 vrp_data/P3533CGB_EST_PARTY\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:39 vrp_data/P3533CGB_EST_PARTY_DETL_RLTN\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:40 vrp_data/P3533CGB_LBR_NOTE\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:36 vrp_data/P3533CGB_LOS_EST\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:41 vrp_data/P3533CGB_MSG\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:41 vrp_data/P3533CGB_NON_OEM\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:42 vrp_data/P3533CGB_OPT\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:43 vrp_data/P3533CGB_RATE\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:43 vrp_data/P3533CGB_TAX\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-08 14:44 vrp_data/P3533CGB_TTL\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:08 vrp_data/P3533DED_AUTO_EST_SUM\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:06 vrp_data/P3533DED_EST_PARTY\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:05 vrp_data/P3533DED_EST_PARTY_DETL_RLTN\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:07 vrp_data/P3533DED_LBR_NOTE\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:01 vrp_data/P3533DED_LOS_EST\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:10 vrp_data/P3533DED_MSG\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:08 vrp_data/P3533DED_NON_OEM\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:01 vrp_data/P3533DED_OPT\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:07 vrp_data/P3533DED_RATE\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:05 vrp_data/P3533DED_TAX\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 09:09 vrp_data/P3533DED_TTL\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 13:19 vrp_data/P3533EEB_DETL\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-10 14:05 vrp_data/P3533EED_DETL\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 13:31 vrp_data/Y1753CAA_DETL\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-23 14:16 vrp_data/Y1753CAA_LOS_EST\r\n",
      "drwxr-xr-x   - kesj kesj          0 2014-10-28 08:24 vrp_data/Y1753DAA_DETL\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls 'vrp_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 08:29:16 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 08:29:17 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 08:29:17 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 08:29:19 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:29:19 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:29:19 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/0c60e4e0b71ccef82bce42ae1f87c682/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 08:29:21 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/0c60e4e0b71ccef82bce42ae1f87c682/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 08:29:21 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 08:29:21 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 08:29:21 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:29:22 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:29:22 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 08:29:22 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/0c60e4e0b71ccef82bce42ae1f87c682/DETL.avsc\n",
      "14/10/28 08:29:22 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 08:29:23 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 08:29:25 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 08:29:25 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='Y1753DAA' ) )\n",
      "14/10/28 08:30:26 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 08:30:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0156\n",
      "14/10/28 08:30:26 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0156\n",
      "14/10/28 08:30:27 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0156/\n",
      "14/10/28 08:30:27 INFO mapreduce.Job: Running job: job_1412635903408_0156\n",
      "14/10/28 08:30:32 INFO mapreduce.Job: Job job_1412635903408_0156 running in uber mode : false\n",
      "14/10/28 08:30:32 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 08:30:52 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 08:30:58 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 08:31:01 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 08:31:05 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 08:31:21 INFO mapreduce.Job: Job job_1412635903408_0156 completed successfully\n",
      "14/10/28 08:31:21 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=440504\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=521\n",
      "\t\tHDFS: Number of bytes written=24121739\n",
      "\t\tHDFS: Number of read operations=16\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=8\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=4\n",
      "\t\tOther local map tasks=4\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=184688\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=184688\n",
      "\t\tTotal vcore-seconds taken by all map tasks=184688\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=189120512\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=83887\n",
      "\t\tMap output records=83887\n",
      "\t\tInput split bytes=521\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=287\n",
      "\t\tCPU time spent (ms)=28370\n",
      "\t\tPhysical memory (bytes) snapshot=1247162368\n",
      "\t\tVirtual memory (bytes) snapshot=6284312576\n",
      "\t\tTotal committed heap usage (bytes)=2546991104\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=24121739\n",
      "14/10/28 08:31:21 INFO mapreduce.ImportJobBase: Transferred 23.0043 MB in 118.9115 seconds (198.1001 KB/sec)\n",
      "14/10/28 08:31:21 INFO mapreduce.ImportJobBase: Retrieved 83887 records.\n"
     ]
    }
   ],
   "source": [
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='Y1753DAA' )\" --target-dir vrp_data/Y1753DAA_DETLp --split-by DETL_DIM_ID --class-name \"sf.datascience.vrp.avro.export.DETL\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nDETLlines = {}\n",
    "for vcd in listOfVNDRCDS:\n",
    "    if vcd != '':\n",
    "        nDETLlines[vcd]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['910027', '910698', '910848', '911754', 'ARM8192', 'ARM8416',\n",
       "       'ARM8427', 'ARM8512', 'ARM8516', 'ARM8522', 'ARM8530', 'ARM8545',\n",
       "       'Y1753AAA', 'Y1753BAA', 'Y1753BAD', 'Y1753CAA', 'Y1753CAD',\n",
       "       'Y1753DAA', 'Y1753DAD', 'Y2114AER'], \n",
       "      dtype='|S8')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfVNDRCDS = sort(listOfVNDRCDS)\n",
    "lVNDRCDS = listOfVNDRCDS[1:]\n",
    "lVNDRCDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:16:16 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:16:17 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:16:17 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:16:19 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:16:19 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:16:19 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/95baf8ee7f8e74244d359b3b938a6451/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:16:21 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/95baf8ee7f8e74244d359b3b938a6451/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:16:21 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:16:21 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:16:21 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:16:23 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:16:23 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:16:23 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/95baf8ee7f8e74244d359b3b938a6451/DETL.avsc\n",
      "14/10/28 09:16:23 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:16:23 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:16:25 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:16:25 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='910027' ) )\n",
      "14/10/28 09:17:09 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:17:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0177\n",
      "14/10/28 09:17:09 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0177\n",
      "14/10/28 09:17:09 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0177/\n",
      "14/10/28 09:17:09 INFO mapreduce.Job: Running job: job_1412635903408_0177\n",
      "14/10/28 09:17:15 INFO mapreduce.Job: Job job_1412635903408_0177 running in uber mode : false\n",
      "14/10/28 09:17:15 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:17:34 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 09:17:34 INFO mapreduce.Job: Task Id : attempt_1412635903408_0177_m_000001_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 324237\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:17:35 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:17:36 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:17:39 INFO mapreduce.Job: Task Id : attempt_1412635903408_0177_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 5734\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:17:40 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:17:51 INFO mapreduce.Job: Task Id : attempt_1412635903408_0177_m_000001_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 164306\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:17:59 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:18:02 INFO mapreduce.Job: Task Id : attempt_1412635903408_0177_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 76075\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:18:03 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:18:08 INFO mapreduce.Job: Task Id : attempt_1412635903408_0177_m_000001_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 170999\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:18:23 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:18:25 INFO mapreduce.Job: Task Id : attempt_1412635903408_0177_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 143215\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:18:26 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:18:27 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:18:27 INFO mapreduce.Job: Job job_1412635903408_0177 failed with state FAILED due to: Task failed task_1412635903408_0177_m_000001\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 09:18:27 INFO mapreduce.Job: Counters: 9\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=2\n",
      "\t\tLaunched map tasks=9\n",
      "\t\tOther local map tasks=9\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=271241\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=271241\n",
      "\t\tTotal vcore-seconds taken by all map tasks=271241\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=277750784\n",
      "14/10/28 09:18:27 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 09:18:27 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 124.3016 seconds (0 bytes/sec)\n",
      "14/10/28 09:18:27 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead\n",
      "14/10/28 09:18:27 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 09:18:27 ERROR tool.ImportTool: Error during import: Import job failed!\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:18:29 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:18:30 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:18:30 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:18:32 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:18:32 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:18:32 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/488d157c3c467694937b3d29e56168d0/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:18:34 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/488d157c3c467694937b3d29e56168d0/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:18:34 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:18:34 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:18:34 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:18:35 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:18:35 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:18:35 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/488d157c3c467694937b3d29e56168d0/DETL.avsc\n",
      "14/10/28 09:18:35 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:18:36 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:18:38 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:18:38 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='910698' ) )\n",
      "14/10/28 09:19:02 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:19:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0178\n",
      "14/10/28 09:19:02 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0178\n",
      "14/10/28 09:19:02 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0178/\n",
      "14/10/28 09:19:02 INFO mapreduce.Job: Running job: job_1412635903408_0178\n",
      "14/10/28 09:19:09 INFO mapreduce.Job: Job job_1412635903408_0178 running in uber mode : false\n",
      "14/10/28 09:19:09 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:19:24 INFO mapreduce.Job: Task Id : attempt_1412635903408_0178_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 301007\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:19:29 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:19:38 INFO mapreduce.Job: Task Id : attempt_1412635903408_0178_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 140608\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:19:53 INFO mapreduce.Job: Task Id : attempt_1412635903408_0178_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 177531\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:20:09 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:20:09 INFO mapreduce.Job: Job job_1412635903408_0178 failed with state FAILED due to: Task failed task_1412635903408_0178_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 09:20:09 INFO mapreduce.Job: Counters: 9\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=4\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=7\n",
      "\t\tOther local map tasks=7\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=225963\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=225963\n",
      "\t\tTotal vcore-seconds taken by all map tasks=225963\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=231386112\n",
      "14/10/28 09:20:09 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 09:20:09 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 93.8456 seconds (0 bytes/sec)\n",
      "14/10/28 09:20:09 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead\n",
      "14/10/28 09:20:09 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 09:20:09 ERROR tool.ImportTool: Error during import: Import job failed!\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:20:11 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:20:12 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:20:12 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:20:14 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:20:14 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:20:14 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/91e0b20fea6e3554f1342c0c3acd9eab/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:20:16 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/91e0b20fea6e3554f1342c0c3acd9eab/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:20:16 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:20:16 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:20:16 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:20:17 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:20:17 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:20:17 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/91e0b20fea6e3554f1342c0c3acd9eab/DETL.avsc\n",
      "14/10/28 09:20:17 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:20:17 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:20:19 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:20:19 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='910848' ) )\n",
      "14/10/28 09:21:12 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:21:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0179\n",
      "14/10/28 09:21:13 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0179\n",
      "14/10/28 09:21:13 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0179/\n",
      "14/10/28 09:21:13 INFO mapreduce.Job: Running job: job_1412635903408_0179\n",
      "14/10/28 09:21:19 INFO mapreduce.Job: Job job_1412635903408_0179 running in uber mode : false\n",
      "14/10/28 09:21:19 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:21:39 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:23:11 INFO mapreduce.Job: Job job_1412635903408_0179 completed successfully\n",
      "14/10/28 09:23:12 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=440484\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=521\n",
      "\t\tHDFS: Number of bytes written=426462522\n",
      "\t\tHDFS: Number of read operations=16\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=8\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=4\n",
      "\t\tOther local map tasks=4\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=355556\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=355556\n",
      "\t\tTotal vcore-seconds taken by all map tasks=355556\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=364089344\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1399664\n",
      "\t\tMap output records=1399664\n",
      "\t\tInput split bytes=521\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=1111\n",
      "\t\tCPU time spent (ms)=120410\n",
      "\t\tPhysical memory (bytes) snapshot=866095104\n",
      "\t\tVirtual memory (bytes) snapshot=6301298688\n",
      "\t\tTotal committed heap usage (bytes)=2128084992\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=426462522\n",
      "14/10/28 09:23:12 INFO mapreduce.ImportJobBase: Transferred 406.7064 MB in 174.3925 seconds (2.3321 MB/sec)\n",
      "14/10/28 09:23:12 INFO mapreduce.ImportJobBase: Retrieved 1399664 records.\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:23:13 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:23:15 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:23:15 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:23:16 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:23:16 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:23:16 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/6e59da1bb800a78795a54567518f3b51/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:23:18 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/6e59da1bb800a78795a54567518f3b51/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:23:18 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:23:18 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:23:18 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:23:19 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:23:20 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:23:20 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/6e59da1bb800a78795a54567518f3b51/DETL.avsc\n",
      "14/10/28 09:23:20 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:23:20 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:23:22 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:23:22 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='911754' ) )\n",
      "14/10/28 09:23:46 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:23:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0180\n",
      "14/10/28 09:23:46 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0180\n",
      "14/10/28 09:23:46 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0180/\n",
      "14/10/28 09:23:46 INFO mapreduce.Job: Running job: job_1412635903408_0180\n",
      "14/10/28 09:23:53 INFO mapreduce.Job: Job job_1412635903408_0180 running in uber mode : false\n",
      "14/10/28 09:23:53 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:24:09 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 09:24:09 INFO mapreduce.Job: Task Id : attempt_1412635903408_0180_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 190511\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:24:09 INFO mapreduce.Job: Task Id : attempt_1412635903408_0180_m_000001_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 172430\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:24:10 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:24:12 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 09:24:13 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:24:24 INFO mapreduce.Job: Task Id : attempt_1412635903408_0180_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 165812\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:24:24 INFO mapreduce.Job: Task Id : attempt_1412635903408_0180_m_000001_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 157619\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:24:39 INFO mapreduce.Job: Task Id : attempt_1412635903408_0180_m_000001_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 202165\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:24:40 INFO mapreduce.Job: Task Id : attempt_1412635903408_0180_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 231748\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:24:54 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:24:54 INFO mapreduce.Job: Job job_1412635903408_0180 failed with state FAILED due to: Task failed task_1412635903408_0180_m_000001\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 09:24:54 INFO mapreduce.Job: Counters: 12\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=10\n",
      "\t\tOther local map tasks=10\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=227573\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=227573\n",
      "\t\tTotal vcore-seconds taken by all map tasks=227573\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=233034752\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "14/10/28 09:24:54 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 09:24:54 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 94.3174 seconds (0 bytes/sec)\n",
      "14/10/28 09:24:54 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 09:24:54 ERROR tool.ImportTool: Error during import: Import job failed!\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:24:56 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:24:57 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:24:57 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:24:59 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:24:59 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:24:59 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/b5a38ec458960dee7a32d2174c92b58f/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:25:01 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/b5a38ec458960dee7a32d2174c92b58f/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:25:01 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:25:01 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:25:01 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:25:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:25:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:25:03 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/b5a38ec458960dee7a32d2174c92b58f/DETL.avsc\n",
      "14/10/28 09:25:03 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:25:03 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:25:05 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:25:05 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8192' ) )\n",
      "14/10/28 09:25:30 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:25:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0181\n",
      "14/10/28 09:25:31 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0181\n",
      "14/10/28 09:25:31 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0181/\n",
      "14/10/28 09:25:31 INFO mapreduce.Job: Running job: job_1412635903408_0181\n",
      "14/10/28 09:25:37 INFO mapreduce.Job: Job job_1412635903408_0181 running in uber mode : false\n",
      "14/10/28 09:25:37 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:25:57 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:29:15 INFO mapreduce.Job: Job job_1412635903408_0181 completed successfully\n",
      "14/10/28 09:29:15 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=440477\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=521\n",
      "\t\tHDFS: Number of bytes written=941463386\n",
      "\t\tHDFS: Number of read operations=16\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=8\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=4\n",
      "\t\tOther local map tasks=4\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=662637\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=662637\n",
      "\t\tTotal vcore-seconds taken by all map tasks=662637\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=678540288\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=3199039\n",
      "\t\tMap output records=3199039\n",
      "\t\tInput split bytes=521\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=2634\n",
      "\t\tCPU time spent (ms)=239890\n",
      "\t\tPhysical memory (bytes) snapshot=728133632\n",
      "\t\tVirtual memory (bytes) snapshot=6315352064\n",
      "\t\tTotal committed heap usage (bytes)=1992818688\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=941463386\n",
      "14/10/28 09:29:15 INFO mapreduce.ImportJobBase: Transferred 897.8495 MB in 252.7197 seconds (3.5527 MB/sec)\n",
      "14/10/28 09:29:15 INFO mapreduce.ImportJobBase: Retrieved 3199039 records.\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:29:17 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:29:18 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:29:18 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:29:20 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:20 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:20 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/197768f6484d56ccd203cfb39c598535/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:29:22 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/197768f6484d56ccd203cfb39c598535/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:29:22 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:29:22 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:29:22 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:23 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:23 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:23 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/197768f6484d56ccd203cfb39c598535/DETL.avsc\n",
      "14/10/28 09:29:23 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:29:24 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:29:24 WARN security.UserGroupInformation: PriviledgedActionException as:kesj (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://ac00h1pname02.opr.statefarm.org:8020/user/kesj/vrp_data/ARM8416_DETL already exists\n",
      "14/10/28 09:29:24 ERROR tool.ImportTool: Encountered IOException running import job: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://ac00h1pname02.opr.statefarm.org:8020/user/kesj/vrp_data/ARM8416_DETL already exists\n",
      "\tat org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:458)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:343)\n",
      "\tat org.apache.hadoop.mapreduce.Job$10.run(Job.java:1295)\n",
      "\tat org.apache.hadoop.mapreduce.Job$10.run(Job.java:1292)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1292)\n",
      "\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1313)\n",
      "\tat org.apache.sqoop.mapreduce.ImportJobBase.doSubmitJob(ImportJobBase.java:186)\n",
      "\tat org.apache.sqoop.mapreduce.ImportJobBase.runJob(ImportJobBase.java:159)\n",
      "\tat org.apache.sqoop.mapreduce.ImportJobBase.runImport(ImportJobBase.java:247)\n",
      "\tat org.apache.sqoop.manager.SqlManager.importTable(SqlManager.java:614)\n",
      "\tat org.apache.sqoop.manager.Db2Manager.importTable(Db2Manager.java:65)\n",
      "\tat org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:413)\n",
      "\tat org.apache.sqoop.tool.ImportTool.run(ImportTool.java:506)\n",
      "\tat org.apache.sqoop.Sqoop.run(Sqoop.java:147)\n",
      "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n",
      "\tat org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183)\n",
      "\tat org.apache.sqoop.Sqoop.runTool(Sqoop.java:222)\n",
      "\tat org.apache.sqoop.Sqoop.runTool(Sqoop.java:231)\n",
      "\tat org.apache.sqoop.Sqoop.main(Sqoop.java:240)\n",
      "\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:29:25 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:29:27 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:29:27 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:29:28 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:28 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:28 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/01b105b9cdd5152ae6ef5f247c5bb2ad/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:29:31 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/01b105b9cdd5152ae6ef5f247c5bb2ad/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:29:31 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:29:31 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:29:31 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:32 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:32 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:29:32 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/01b105b9cdd5152ae6ef5f247c5bb2ad/DETL.avsc\n",
      "14/10/28 09:29:32 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:29:32 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:29:34 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:29:34 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8427' ) )\n",
      "14/10/28 09:30:08 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:30:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0182\n",
      "14/10/28 09:30:09 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0182\n",
      "14/10/28 09:30:09 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0182/\n",
      "14/10/28 09:30:09 INFO mapreduce.Job: Running job: job_1412635903408_0182\n",
      "14/10/28 09:30:15 INFO mapreduce.Job: Job job_1412635903408_0182 running in uber mode : false\n",
      "14/10/28 09:30:15 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:30:38 INFO mapreduce.Job: Task Id : attempt_1412635903408_0182_m_000001_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 54153\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:30:41 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:30:41 INFO mapreduce.Job: Task Id : attempt_1412635903408_0182_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 99158\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:30:42 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:30:55 INFO mapreduce.Job: Task Id : attempt_1412635903408_0182_m_000001_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 219451\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:31:01 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:31:02 INFO mapreduce.Job: Task Id : attempt_1412635903408_0182_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 27577\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:31:03 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:31:15 INFO mapreduce.Job: Task Id : attempt_1412635903408_0182_m_000001_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 238526\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:31:21 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:31:22 INFO mapreduce.Job: Task Id : attempt_1412635903408_0182_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 177013\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:31:23 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:31:33 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:31:33 INFO mapreduce.Job: Job job_1412635903408_0182 failed with state FAILED due to: Task failed task_1412635903408_0182_m_000001\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 09:31:34 INFO mapreduce.Job: Counters: 12\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=10\n",
      "\t\tOther local map tasks=10\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=293222\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=293222\n",
      "\t\tTotal vcore-seconds taken by all map tasks=293222\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=300259328\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "14/10/28 09:31:34 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 09:31:34 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 121.4622 seconds (0 bytes/sec)\n",
      "14/10/28 09:31:34 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 09:31:34 ERROR tool.ImportTool: Error during import: Import job failed!\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:31:35 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:31:36 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:31:36 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:31:38 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:38 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:38 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/82cb8c90410726a8d791262624e27d5c/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:31:40 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/82cb8c90410726a8d791262624e27d5c/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:31:40 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:31:40 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:31:40 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:41 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:41 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:42 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/82cb8c90410726a8d791262624e27d5c/DETL.avsc\n",
      "14/10/28 09:31:42 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:31:42 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:31:42 WARN security.UserGroupInformation: PriviledgedActionException as:kesj (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://ac00h1pname02.opr.statefarm.org:8020/user/kesj/vrp_data/ARM8512_DETL already exists\n",
      "14/10/28 09:31:42 ERROR tool.ImportTool: Encountered IOException running import job: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://ac00h1pname02.opr.statefarm.org:8020/user/kesj/vrp_data/ARM8512_DETL already exists\n",
      "\tat org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:458)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:343)\n",
      "\tat org.apache.hadoop.mapreduce.Job$10.run(Job.java:1295)\n",
      "\tat org.apache.hadoop.mapreduce.Job$10.run(Job.java:1292)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1292)\n",
      "\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1313)\n",
      "\tat org.apache.sqoop.mapreduce.ImportJobBase.doSubmitJob(ImportJobBase.java:186)\n",
      "\tat org.apache.sqoop.mapreduce.ImportJobBase.runJob(ImportJobBase.java:159)\n",
      "\tat org.apache.sqoop.mapreduce.ImportJobBase.runImport(ImportJobBase.java:247)\n",
      "\tat org.apache.sqoop.manager.SqlManager.importTable(SqlManager.java:614)\n",
      "\tat org.apache.sqoop.manager.Db2Manager.importTable(Db2Manager.java:65)\n",
      "\tat org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:413)\n",
      "\tat org.apache.sqoop.tool.ImportTool.run(ImportTool.java:506)\n",
      "\tat org.apache.sqoop.Sqoop.run(Sqoop.java:147)\n",
      "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n",
      "\tat org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183)\n",
      "\tat org.apache.sqoop.Sqoop.runTool(Sqoop.java:222)\n",
      "\tat org.apache.sqoop.Sqoop.runTool(Sqoop.java:231)\n",
      "\tat org.apache.sqoop.Sqoop.main(Sqoop.java:240)\n",
      "\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:31:44 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:31:45 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:31:45 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:31:47 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:47 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:47 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/eecba86d23b3e86f1cfac233cc130e8e/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:31:49 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/eecba86d23b3e86f1cfac233cc130e8e/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:31:49 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:31:49 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:31:49 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:50 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:50 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:31:50 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/eecba86d23b3e86f1cfac233cc130e8e/DETL.avsc\n",
      "14/10/28 09:31:50 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:31:51 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:31:53 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:31:53 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8516' ) )\n",
      "14/10/28 09:32:22 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:32:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0183\n",
      "14/10/28 09:32:22 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0183\n",
      "14/10/28 09:32:22 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0183/\n",
      "14/10/28 09:32:22 INFO mapreduce.Job: Running job: job_1412635903408_0183\n",
      "14/10/28 09:32:28 INFO mapreduce.Job: Job job_1412635903408_0183 running in uber mode : false\n",
      "14/10/28 09:32:28 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:32:48 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:32:48 INFO mapreduce.Job: Task Id : attempt_1412635903408_0183_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 319844\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:32:50 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:33:09 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:33:09 INFO mapreduce.Job: Task Id : attempt_1412635903408_0183_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 70710\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:33:10 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:33:29 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:33:30 INFO mapreduce.Job: Task Id : attempt_1412635903408_0183_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 81701\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:33:31 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:33:53 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:33:53 INFO mapreduce.Job: Job job_1412635903408_0183 failed with state FAILED due to: Task failed task_1412635903408_0183_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 09:33:53 INFO mapreduce.Job: Counters: 9\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=4\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=7\n",
      "\t\tOther local map tasks=7\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=324008\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=324008\n",
      "\t\tTotal vcore-seconds taken by all map tasks=324008\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=331784192\n",
      "14/10/28 09:33:53 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 09:33:53 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 122.6549 seconds (0 bytes/sec)\n",
      "14/10/28 09:33:53 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead\n",
      "14/10/28 09:33:53 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 09:33:53 ERROR tool.ImportTool: Error during import: Import job failed!\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:33:55 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:33:56 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:33:56 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:33:58 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:33:58 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:33:58 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/14e122149579577b1fdc738844a283cc/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:34:00 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/14e122149579577b1fdc738844a283cc/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:34:00 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:34:00 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:34:00 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:34:01 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:34:01 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:34:01 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/14e122149579577b1fdc738844a283cc/DETL.avsc\n",
      "14/10/28 09:34:01 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:34:02 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:34:04 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:34:04 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8522' ) )\n",
      "14/10/28 09:34:32 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:34:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0184\n",
      "14/10/28 09:34:33 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0184\n",
      "14/10/28 09:34:33 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0184/\n",
      "14/10/28 09:34:33 INFO mapreduce.Job: Running job: job_1412635903408_0184\n",
      "14/10/28 09:34:38 INFO mapreduce.Job: Job job_1412635903408_0184 running in uber mode : false\n",
      "14/10/28 09:34:38 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:34:55 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 09:34:55 INFO mapreduce.Job: Task Id : attempt_1412635903408_0184_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 128501\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:34:56 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:34:58 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:35:02 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 09:35:12 INFO mapreduce.Job: Task Id : attempt_1412635903408_0184_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 158598\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:35:29 INFO mapreduce.Job: Task Id : attempt_1412635903408_0184_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 138776\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:35:47 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:35:47 INFO mapreduce.Job: Job job_1412635903408_0184 failed with state FAILED due to: Task failed task_1412635903408_0184_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 09:35:47 INFO mapreduce.Job: Counters: 9\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=4\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=7\n",
      "\t\tOther local map tasks=7\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=260794\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=260794\n",
      "\t\tTotal vcore-seconds taken by all map tasks=260794\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=267053056\n",
      "14/10/28 09:35:47 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 09:35:47 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 105.9543 seconds (0 bytes/sec)\n",
      "14/10/28 09:35:47 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead\n",
      "14/10/28 09:35:47 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 09:35:47 ERROR tool.ImportTool: Error during import: Import job failed!\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:35:49 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:35:50 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:35:50 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:35:54 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:35:54 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:35:54 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/46e3ac84b9f7ef58b69e896b3d45a2c5/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:35:56 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/46e3ac84b9f7ef58b69e896b3d45a2c5/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:35:56 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:35:57 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:35:57 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:35:58 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:35:58 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:35:58 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/46e3ac84b9f7ef58b69e896b3d45a2c5/DETL.avsc\n",
      "14/10/28 09:35:58 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:35:58 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:36:01 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:36:01 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8530' ) )\n",
      "14/10/28 09:36:28 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:36:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0185\n",
      "14/10/28 09:36:28 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0185\n",
      "14/10/28 09:36:28 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0185/\n",
      "14/10/28 09:36:28 INFO mapreduce.Job: Running job: job_1412635903408_0185\n",
      "14/10/28 09:36:34 INFO mapreduce.Job: Job job_1412635903408_0185 running in uber mode : false\n",
      "14/10/28 09:36:34 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:36:51 INFO mapreduce.Job: Task Id : attempt_1412635903408_0185_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 87099\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:167)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:36:52 INFO mapreduce.Job: Task Id : attempt_1412635903408_0185_m_000001_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 317813\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:167)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:36:54 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:37:09 INFO mapreduce.Job: Task Id : attempt_1412635903408_0185_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 181011\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:167)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:37:11 INFO mapreduce.Job: Task Id : attempt_1412635903408_0185_m_000001_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 112735\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:167)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:37:25 INFO mapreduce.Job: Task Id : attempt_1412635903408_0185_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 155591\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:167)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:37:28 INFO mapreduce.Job: Task Id : attempt_1412635903408_0185_m_000001_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 115774\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:167)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:37:43 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:37:43 INFO mapreduce.Job: Job job_1412635903408_0185 failed with state FAILED due to: Task failed task_1412635903408_0185_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 09:37:43 INFO mapreduce.Job: Counters: 12\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=10\n",
      "\t\tOther local map tasks=10\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=256781\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=256781\n",
      "\t\tTotal vcore-seconds taken by all map tasks=256781\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=262943744\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "14/10/28 09:37:43 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 09:37:43 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 104.6806 seconds (0 bytes/sec)\n",
      "14/10/28 09:37:43 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 09:37:43 ERROR tool.ImportTool: Error during import: Import job failed!\n",
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 09:37:45 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 09:37:46 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 09:37:46 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 09:37:47 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:37:48 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:37:48 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/3dd6a03393f4f511e8d3a1f4e1a26793/sf/datascience/vrp/avro/export/DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 09:37:50 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/3dd6a03393f4f511e8d3a1f4e1a26793/sf.datascience.vrp.avro.export.DETL.jar\n",
      "14/10/28 09:37:50 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 09:37:50 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 09:37:50 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:37:51 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:37:51 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 09:37:51 INFO mapreduce.DataDrivenImportJob: Writing Avro schema file: /tmp/sqoop-kesj/compile/3dd6a03393f4f511e8d3a1f4e1a26793/DETL.avsc\n",
      "14/10/28 09:37:52 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 09:37:52 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 09:37:53 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 09:37:53 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8545' ) )\n",
      "14/10/28 09:38:17 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 09:38:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0186\n",
      "14/10/28 09:38:18 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0186\n",
      "14/10/28 09:38:18 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0186/\n",
      "14/10/28 09:38:18 INFO mapreduce.Job: Running job: job_1412635903408_0186\n",
      "14/10/28 09:38:24 INFO mapreduce.Job: Job job_1412635903408_0186 running in uber mode : false\n",
      "14/10/28 09:38:24 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 09:38:40 INFO mapreduce.Job: Task Id : attempt_1412635903408_0186_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 304946\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:38:40 INFO mapreduce.Job: Task Id : attempt_1412635903408_0186_m_000001_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 233434\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:38:43 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 09:38:44 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 09:38:56 INFO mapreduce.Job: Task Id : attempt_1412635903408_0186_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 321176\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:38:56 INFO mapreduce.Job: Task Id : attempt_1412635903408_0186_m_000001_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 68616\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:39:11 INFO mapreduce.Job: Task Id : attempt_1412635903408_0186_m_000001_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 50447\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:39:11 INFO mapreduce.Job: Task Id : attempt_1412635903408_0186_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat sf.datascience.vrp.avro.export.DETL.readFields(DETL.java:900)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 5053\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 09:39:27 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 09:39:27 INFO mapreduce.Job: Job job_1412635903408_0186 failed with state FAILED due to: Task failed task_1412635903408_0186_m_000001\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 09:39:27 INFO mapreduce.Job: Counters: 12\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=10\n",
      "\t\tOther local map tasks=10\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=237132\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=237132\n",
      "\t\tTotal vcore-seconds taken by all map tasks=237132\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=242823168\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "14/10/28 09:39:27 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead\n",
      "14/10/28 09:39:27 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 95.9319 seconds (0 bytes/sec)\n",
      "14/10/28 09:39:27 INFO mapreduce.ImportJobBase: Retrieved 0 records.\n",
      "14/10/28 09:39:27 ERROR tool.ImportTool: Error during import: Import job failed!\n"
     ]
    }
   ],
   "source": [
    "for vndrCd in lVNDRCDS[:12]:\n",
    "    tgt = 'vrp_data/'+vndrCd+'_DETL'\n",
    "    wclause = '\"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='+\"'\"+vndrCd+\"'\"+' )\"'\n",
    "    #print wclause\n",
    "    #print vndrCd,tgt\n",
    "    #!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD=910027')\" --target-dir {tgt} --split-by DETL_DIM_ID --class-name \"sf.datascience.vrp.avro.export.DETL\" \n",
    "    !sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL --where {wclause} --target-dir {tgt} --split-by DETL_DIM_ID --class-name \"sf.datascience.vrp.avro.export.DETL\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try avoiding AVRO for one that works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 10:32:06 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 10:32:08 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 10:32:08 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 10:32:09 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 10:32:09 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 10:32:09 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/233f47330df3f554e5f306e29854b434/FDWATOMCAE_DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 10:32:12 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/233f47330df3f554e5f306e29854b434/FDWATOMCAE.DETL.jar\n",
      "14/10/28 10:32:12 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 10:32:12 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 10:32:12 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 10:32:12 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 10:32:12 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 10:32:14 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 10:32:14 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='Y1753CAD' ) )\n",
      "14/10/28 10:34:17 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 10:34:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0187\n",
      "14/10/28 10:34:18 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0187\n",
      "14/10/28 10:34:18 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0187/\n",
      "14/10/28 10:34:18 INFO mapreduce.Job: Running job: job_1412635903408_0187\n",
      "14/10/28 10:34:24 INFO mapreduce.Job: Job job_1412635903408_0187 running in uber mode : false\n",
      "14/10/28 10:34:24 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 10:34:53 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 10:34:55 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 10:35:02 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 10:35:05 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 10:35:21 INFO mapreduce.Job: Job job_1412635903408_0187 completed successfully\n",
      "14/10/28 10:35:21 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=414220\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=521\n",
      "\t\tHDFS: Number of bytes written=17214932\n",
      "\t\tHDFS: Number of read operations=16\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=8\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=4\n",
      "\t\tOther local map tasks=4\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=212461\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=212461\n",
      "\t\tTotal vcore-seconds taken by all map tasks=212461\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=217560064\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=39947\n",
      "\t\tMap output records=39947\n",
      "\t\tInput split bytes=521\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=458\n",
      "\t\tCPU time spent (ms)=27540\n",
      "\t\tPhysical memory (bytes) snapshot=1310494720\n",
      "\t\tVirtual memory (bytes) snapshot=6318419968\n",
      "\t\tTotal committed heap usage (bytes)=2772434944\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=17214932\n",
      "14/10/28 10:35:21 INFO mapreduce.ImportJobBase: Transferred 16.4174 MB in 188.9971 seconds (88.9509 KB/sec)\n",
      "14/10/28 10:35:21 INFO mapreduce.ImportJobBase: Retrieved 39947 records.\n"
     ]
    }
   ],
   "source": [
    "vndrCd = 'Y1753CAD'\n",
    "tgt = 'vrp/'+vndrCd+'_DETL'\n",
    "wclause = '\"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='+\"'\"+vndrCd+\"'\"+' )\"'\n",
    "\n",
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --table FDWATOMCAE.DETL --where {wclause} --target-dir {tgt} --split-by DETL_DIM_ID --fields-terminated-by , --escaped-by \\\\ --enclosed-by '\\\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /opt/cloudera/parcels/CDH-5.0.0-1.cdh5.0.0.p0.47/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.\n",
      "Please set $ACCUMULO_HOME to the root of your Accumulo installation.\n",
      "14/10/28 10:37:05 INFO sqoop.Sqoop: Running Sqoop version: 1.4.4-cdh5.0.0\n",
      "14/10/28 10:37:06 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "14/10/28 10:37:06 INFO tool.CodeGenTool: Beginning code generation\n",
      "14/10/28 10:37:07 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 10:37:07 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 10:37:08 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "Note: /tmp/sqoop-kesj/compile/14f35bc59a29fb69d5feaf84d4c3ef29/FDWATOMCAE_DETL.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "14/10/28 10:37:10 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-kesj/compile/14f35bc59a29fb69d5feaf84d4c3ef29/FDWATOMCAE.DETL.jar\n",
      "14/10/28 10:37:10 INFO mapreduce.ImportJobBase: Beginning import of FDWATOMCAE.DETL\n",
      "14/10/28 10:37:10 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "14/10/28 10:37:10 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM FDWATOMCAE.DETL AS t WHERE 1=0\n",
      "14/10/28 10:37:10 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "14/10/28 10:37:10 INFO client.RMProxy: Connecting to ResourceManager at ac00h1pjtkr01.opr.statefarm.org/10.36.219.119:8032\n",
      "14/10/28 10:37:12 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "14/10/28 10:37:12 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(DETL_DIM_ID), MAX(DETL_DIM_ID) FROM FDWATOMCAE.DETL WHERE ( LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='Y1753AAA' ) )\n",
      "14/10/28 10:38:22 INFO mapreduce.JobSubmitter: number of splits:4\n",
      "14/10/28 10:38:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1412635903408_0188\n",
      "14/10/28 10:38:22 INFO impl.YarnClientImpl: Submitted application application_1412635903408_0188\n",
      "14/10/28 10:38:22 INFO mapreduce.Job: The url to track the job: http://ac00h1pjtkr01.opr.statefarm.org:8088/proxy/application_1412635903408_0188/\n",
      "14/10/28 10:38:22 INFO mapreduce.Job: Running job: job_1412635903408_0188\n",
      "14/10/28 10:38:28 INFO mapreduce.Job: Job job_1412635903408_0188 running in uber mode : false\n",
      "14/10/28 10:38:28 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 10:39:25 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 10:39:27 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "14/10/28 10:39:27 INFO mapreduce.Job: Task Id : attempt_1412635903408_0188_m_000000_0, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat FDWATOMCAE_DETL.readFields(FDWATOMCAE_DETL.java:899)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 35212\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 10:39:30 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "14/10/28 10:39:36 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "14/10/28 10:39:37 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 10:39:48 INFO mapreduce.Job: Task Id : attempt_1412635903408_0188_m_000000_1, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat FDWATOMCAE_DETL.readFields(FDWATOMCAE_DETL.java:899)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 251577\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 10:40:09 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 10:40:10 INFO mapreduce.Job: Task Id : attempt_1412635903408_0188_m_000000_2, Status : FAILED\n",
      "Error: java.io.IOException: SQLException in nextKeyValue\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:279)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
      "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
      "\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
      "Caused by: com.ibm.db2.jcc.am.SqlException: [jcc][t4][1065][12306][4.15.82] Caught java.io.CharConversionException.  See attached Throwable for details. ERRORCODE=-4220, SQLSTATE=null\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:680)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:60)\n",
      "\tat com.ibm.db2.jcc.am.fd.a(fd.java:112)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2870)\n",
      "\tat com.ibm.db2.jcc.am.jc.p(jc.java:527)\n",
      "\tat com.ibm.db2.jcc.am.jc.N(jc.java:1563)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getStringX(ResultSet.java:1153)\n",
      "\tat com.ibm.db2.jcc.am.ResultSet.getString(ResultSet.java:1128)\n",
      "\tat org.apache.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:71)\n",
      "\tat com.cloudera.sqoop.lib.JdbcWritableBridge.readString(JdbcWritableBridge.java:61)\n",
      "\tat FDWATOMCAE_DETL.readFields(FDWATOMCAE_DETL.java:899)\n",
      "\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:246)\n",
      "\t... 12 more\n",
      "Caused by: java.nio.charset.MalformedInputException: Input length = 126989\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:19)\n",
      "\tat com.ibm.db2.jcc.am.jc.a(jc.java:2862)\n",
      "\t... 20 more\n",
      "Caused by: sun.io.MalformedInputException\n",
      "\tat sun.io.ByteToCharUTF8.convert(ByteToCharUTF8.java:105)\n",
      "\tat com.ibm.db2.jcc.am.r.a(r.java:16)\n",
      "\t... 21 more\n",
      "\n",
      "14/10/28 10:40:11 INFO mapreduce.Job:  map 75% reduce 0%\n",
      "14/10/28 10:40:29 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "14/10/28 10:40:30 INFO mapreduce.Job: Job job_1412635903408_0188 failed with state FAILED due to: Task failed task_1412635903408_0188_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "14/10/28 10:40:30 INFO mapreduce.Job: Counters: 31\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=310665\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=391\n",
      "\t\tHDFS: Number of bytes written=13369310\n",
      "\t\tHDFS: Number of read operations=12\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=6\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=4\n",
      "\t\tLaunched map tasks=7\n",
      "\t\tOther local map tasks=7\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=384581\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=384581\n",
      "\t\tTotal vcore-seconds taken by all map tasks=384581\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=393810944\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=31040\n",
      "\t\tMap output records=31040\n",
      "\t\tInput split bytes=391\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=359\n",
      "\t\tCPU time spent (ms)=20700\n",
      "\t\tPhysical memory (bytes) snapshot=925114368\n",
      "\t\tVirtual memory (bytes) snapshot=4735975424\n",
      "\t\tTotal committed heap usage (bytes)=1934622720\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=13369310\n",
      "14/10/28 10:40:30 INFO mapreduce.ImportJobBase: Transferred 12.75 MB in 200.4526 seconds (65.1325 KB/sec)\n",
      "14/10/28 10:40:30 INFO mapreduce.ImportJobBase: Retrieved 31040 records.\n",
      "14/10/28 10:40:30 ERROR tool.ImportTool: Error during import: Import job failed!\n"
     ]
    }
   ],
   "source": [
    "vndrCd = 'Y1753AAA'\n",
    "tgt = 'vrp/'+vndrCd+'_DETL'\n",
    "wclause = '\"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='+\"'\"+vndrCd+\"'\"+' )\"'\n",
    "\n",
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --table FDWATOMCAE.DETL --where {wclause} --target-dir {tgt} --split-by DETL_DIM_ID --fields-terminated-by , --escaped-by \\\\ --enclosed-by '\\\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['910027', '910698', '910848', '911754', 'ARM8192', 'ARM8416',\n",
       "       'ARM8427', 'ARM8512', 'ARM8516', 'ARM8522', 'ARM8530', 'ARM8545'], \n",
       "      dtype='|S8')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lVNDRCDS[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8416' )\" --target-dir vrp_data/ARM8416_DETL --split-by DETL_DIM_ID --class-name \"sf.datascience.vrp.avro.export.DETL\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-28 09:23 vrp_data/910848_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-28 09:29 vrp_data/ARM8192_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-10 13:19 vrp_data/P3533EEB_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-10 14:05 vrp_data/P3533EED_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-28 09:00 vrp_data/Y1753BAA_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-28 09:02 vrp_data/Y1753BAD_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-28 09:03 vrp_data/Y1753CAA_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-28 09:05 vrp_data/Y1753CAD_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-28 09:06 vrp_data/Y1753DAA_DETL/_SUCCESS\r\n",
      "Found 1 items\r\n",
      "-rw-r--r--   3 kesj kesj          0 2014-10-28 09:08 vrp_data/Y1753DAD_DETL/_SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls vrp_data/*_DETL/_SUCCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: `vrp_data/Y2*_DETL/_SUCCESS': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls vrp_data/Y2*_DETL/_SUCCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8522' ) and \\$CONDITIONS\" --target-dir vrpdata/ARM8522_DETL --split-by DETL_DIM_ID  --class-name \"sf.datascience.vrp.avro.export.DETL\" --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password {myPSWD} --as-avrodatafile --table FDWATOMCAE.LOS_EST --where \"WHERE VNDR_VEH_CD='ARM8522'\" --target-dir vrp_data/ARM8522_DETLLOS_EST --split-by \"\" --class-name \"sf.datascience.vrp.avro.export.LOS_EST\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for vcd in listOfVNDRCDS[3:]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 10.24.14\n",
    "# looking at pulling all of DETL records?? How big is this?\n",
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --table FDWATOMCAE.DETL  --target-dir vrp/detl --split-by DETL_DIM_ID  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pulling ARM8512\n",
    "sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --table FDWATOMCAE.DETL  --target-dir vrp_data/arm8512_DETL --split-by DETL_DIM_ID   --as-avrodatafile --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8512') and DETL_DIM_ID AND \\$CONDITIONS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sqoop import --connect jdbc:db2://10.96.37.166:60100/FDW2P --username kesj --password-file {nfile} --as-avrodatafile --table FDWATOMCAE.DETL  --where \"LOS_EST_DIM_ID IN ( SELECT LOS_EST_DIM_ID FROM FDWATOMCAE.LOS_EST WHERE VNDR_VEH_CD='ARM8512') and DETL_DIM_ID AND \\$CONDITIONS\" --target-dir vrp/detl --split-by DETL_DIM_ID  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f6606f95b10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#infile = 'data/pg2489.txt'\n",
    "infile = 'sample_data/2701.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "f = sc.textFile(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Call me Ishmael. Some years ago--never mind how long precisely--having'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for lines with Ishmael\n",
    "ishmaelLines = f.filter(lambda line: \"Ishmael\" in line)\n",
    "ishmaelLines.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ishmaelLines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for lines with Ahab\n",
    "ahablines = f.filter(lambda line: \"Ahab\" in line)\n",
    "ahablines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My take on the ampcamp 5 exercises\n",
    "#### data-exploration example\n",
    "http://ampcamp.berkeley.edu/5/exercises/data-exploration-using-spark.html\n",
    "1. load the file into an rdd (already did this above) as f.\n",
    "2. take a peek a the data. Use the take operation of the RDD to get the first `K` Records (here K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'', u'', u'', u'', u'', u'', u'', u'', u'', u'MOBY DICK; OR THE WHALE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make this prettier by transversing the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MOBY DICK; OR THE WHALE\n",
      "\n",
      "By Herman Melville\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ETYMOLOGY.\n",
      "\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\n",
      "\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now. He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with all the gay flags of all\n",
      "the known nations of the world. He loved to dust his old grammars; it\n",
      "somehow mildly reminded him of his mortality.\n",
      "\n",
      "\"While you take in hand to school others, and to teach them by what\n"
     ]
    }
   ],
   "source": [
    "for x in f.take(30):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 3. Find out how many records are in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21715"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* find out the word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = f.flatMap(lambda line: line.split(\" \")).map(lambda word: (word,1)).reduceByKey(lambda a, b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'', 4061),\n",
       " (u'funereal', 1),\n",
       " (u'unscientific', 1),\n",
       " (u'divinely', 2),\n",
       " (u'lime-stone,', 1),\n",
       " (u'shouted,', 1),\n",
       " (u'Virgin.', 2),\n",
       " (u'pitch-pot,', 1),\n",
       " (u'cod-liver', 1),\n",
       " (u'foul', 10)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.take(10\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Pi\n",
    "This example uses the \"throwing darts\" at a circle method. Pick `n` random points in the unit square [(0,0),(1,1)] and see the fraction that fall in the unit circle. This should be equal to $\\pi/4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sample(p):\n",
    "    x,y = np.random(), np.random()\n",
    "    return 1 if x*x + y*y < 1 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 65 in stage 15.0 failed 4 times, most recent failure: Lost task 65.3 in stage 15.0 (TID 1695, da74wbdn08.opr.statefarm.org): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 792, in func\n  File \"<ipython-input-19-a886b70602da>\", line 3, in sample\nTypeError: 'module' object is not callable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 792, in func\n  File \"<ipython-input-19-a886b70602da>\", line 3, in sample\nTypeError: 'module' object is not callable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a2f05c17e258>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Pi is roughly %f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpcount\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    795\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \"\"\"\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[1;32m--> 813\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    307\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    309\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 65 in stage 15.0 failed 4 times, most recent failure: Lost task 65.3 in stage 15.0 (TID 1695, da74wbdn08.opr.statefarm.org): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 792, in func\n  File \"<ipython-input-19-a886b70602da>\", line 3, in sample\nTypeError: 'module' object is not callable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/data/hadoop-data/8/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000012/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 792, in func\n  File \"<ipython-input-19-a886b70602da>\", line 3, in sample\nTypeError: 'module' object is not callable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "pcount=sc.parallelize(xrange(0,1000)).map(sample).reduce(lambda a,b: a+b)\n",
    "print \"Pi is roughly %f\"%(4.0*pcount/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 4 times, most recent failure: Lost task 0.3 in stage 9.0 (TID 267, da74wbdn16.opr.statefarm.org): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/hadoop-data/2/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000018/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/data/hadoop-data/2/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000018/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 317, in func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 1004, in <lambda>\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 1004, in <genexpr>\n  File \"<ipython-input-13-b4b6cc896ae9>\", line 1, in <lambda>\nIndexError: list index out of range\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/hadoop-data/2/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000018/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/data/hadoop-data/2/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000018/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 317, in func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 1004, in <lambda>\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 1004, in <genexpr>\n  File \"<ipython-input-13-b4b6cc896ae9>\", line 1, in <lambda>\nIndexError: list index out of range\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b4b6cc896ae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menPages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"en\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.cache()\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0menPages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \"\"\"\n\u001b[1;32m-> 1004\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36msum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[1;36m6.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m         \"\"\"\n\u001b[1;32m--> 995\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mfold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;31m# to the final reduce call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 869\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \"\"\"\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[1;32m--> 813\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    307\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    309\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 4 times, most recent failure: Lost task 0.3 in stage 9.0 (TID 267, da74wbdn16.opr.statefarm.org): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/hadoop-data/2/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000018/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/data/hadoop-data/2/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000018/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 317, in func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 1004, in <lambda>\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 1004, in <genexpr>\n  File \"<ipython-input-13-b4b6cc896ae9>\", line 1, in <lambda>\nIndexError: list index out of range\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/hadoop-data/2/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000018/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/data/hadoop-data/2/yarn/nm/usercache/kesj/appcache/application_1449878426981_2453/container_e17_1449878426981_2453_01_000018/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 2346, in pipeline_func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 317, in func\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 1004, in <lambda>\n  File \"/san-data/shared/spark/spark-1.6.0-bin-hadoop2.6/python/pyspark/rdd.py\", line 1004, in <genexpr>\n  File \"<ipython-input-13-b4b6cc896ae9>\", line 1, in <lambda>\nIndexError: list index out of range\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "enPages = f.filter(lambda x: x.split(\" \")[1]==\"en\")#.cache()\n",
    "enPages.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call me Ishmael.  Some years ago--never mind how long precisely--\n"
     ]
    }
   ],
   "source": [
    "#ASIDE\n",
    "a = ishmaelLines.first()\n",
    "print a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I say, Queequeg! why don't you speak?  It's I--Ishmael.\"  But all\n"
     ]
    }
   ],
   "source": [
    "c = '\"I say, Queequeg! why don\\'t you speak?  It\\'s I--Ishmael.\"  But all'\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "pattern1 = re.compile(r'\"|[ ]+|; ?|, ?|! ?|\\? ?|\\. ?|--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'I',\n",
       " 'say',\n",
       " 'Queequeg',\n",
       " 'why',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'speak',\n",
       " '',\n",
       " \"It's\",\n",
       " 'I',\n",
       " 'Ishmael',\n",
       " '',\n",
       " '',\n",
       " 'But',\n",
       " 'all']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(pattern1,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IshmWords = ishmaelLines.flatMap(lambda x: re.split(pattern1,x)).filter(lambda x: len(x)>0)\n",
    "IshmWC = IshmWords.map(lambda x: (x, 1)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IshmWC.saveAsTextFile(\"data/ishmaelWC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this: 1\n",
      "all: 3\n",
      "ago: 1\n",
      "backing: 1\n",
      "Some: 1\n",
      "mind: 1\n",
      "didn't: 1\n",
      "rest: 1\n",
      "shouts: 1\n",
      "go: 4\n",
      "say: 2\n",
      "been: 1\n",
      "Call: 1\n",
      "But: 3\n",
      "have: 1\n",
      "dear: 1\n",
      "thyself: 1\n",
      "Ishmael's: 1\n",
      "muttered: 1\n",
      "for: 2\n",
      "oarsman: 1\n",
      "inquire: 1\n",
      "thy: 1\n",
      "explain: 1\n",
      "had: 2\n",
      "long: 1\n",
      "the: 9\n",
      "I: 8\n",
      "read: 1\n",
      "witness: 1\n",
      "which: 1\n",
      "unlettered: 1\n",
      "robe: 1\n",
      "was: 1\n",
      "price: 1\n",
      "Ishmael: 18\n",
      "A: 1\n",
      "me: 2\n",
      "teeth-gnashing: 1\n",
      "may: 1\n",
      "fate: 1\n",
      "infallibly: 1\n",
      "Well: 1\n",
      "dive: 1\n",
      "ye: 2\n",
      "buffalo: 1\n",
      "here: 1\n",
      "Explain: 1\n",
      "So: 1\n",
      "magnanimous: 1\n",
      "awful: 1\n",
      "whale: 1\n",
      "with: 1\n",
      "you: 7\n",
      "is: 1\n",
      "a: 4\n",
      "down: 1\n",
      "myself: 2\n",
      "last: 1\n",
      "would: 1\n",
      "surrenderest: 1\n",
      "these: 1\n",
      "my: 2\n",
      "wherever: 1\n",
      "as: 1\n",
      "thou: 1\n",
      "hypo: 1\n",
      "suppose: 1\n",
      "hope: 1\n",
      "hear: 1\n",
      "Yes: 1\n",
      "Queequeg: 1\n",
      "shaking: 1\n",
      "away: 1\n",
      "vessel: 1\n",
      "gone: 2\n",
      "don't: 2\n",
      "It's: 1\n",
      "Do: 1\n",
      "it: 1\n",
      "years: 1\n",
      "How: 1\n",
      "pieces: 1\n",
      "are: 1\n",
      "in: 1\n",
      "crew: 1\n",
      "precisely: 1\n",
      "full-grown: 1\n",
      "mere: 1\n",
      "out: 1\n",
      "one: 1\n",
      "hundredth: 1\n",
      "said: 2\n",
      "how: 3\n",
      "veritable: 1\n",
      "there: 1\n",
      "three: 1\n",
      "who: 1\n",
      "should: 1\n",
      "to: 8\n",
      "that: 4\n",
      "God: 1\n",
      "before: 1\n",
      "Ha: 1\n",
      "Chaldee: 1\n",
      "then: 1\n",
      "sure: 1\n",
      "deeper: 1\n",
      "than: 1\n",
      "get: 1\n",
      "why: 1\n",
      "never: 1\n",
      "Can: 1\n",
      "speak: 1\n",
      "land: 1\n",
      "if: 1\n",
      "lay: 1\n",
      "be: 2\n",
      "now: 2\n",
      "silver: 1\n",
      "on: 2\n",
      "heaven: 1\n",
      "your: 1\n",
      "name: 1\n",
      "of: 5\n",
      "up: 1\n",
      "hitherto: 1\n",
      "can: 1\n",
      "night: 1\n",
      "whalemen: 1\n",
      "left: 1\n",
      "at: 1\n"
     ]
    }
   ],
   "source": [
    "# print out the K,V pairs\n",
    "for (word, count) in IshmWC.collect():\n",
    "    print \"{0}: {1}\".format(word,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'Ishmael', 18)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IshmWC.filter(lambda x: x[1]> 10).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IshmWC.count() #yields the number of distinct keys (words) in this subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'A', 1),\n",
       " (u'But', 3),\n",
       " (u'Call', 1),\n",
       " (u'Can', 1),\n",
       " (u'Chaldee', 1),\n",
       " (u'Do', 1),\n",
       " (u'Explain', 1),\n",
       " (u'God', 1),\n",
       " (u'Ha', 1),\n",
       " (u'How', 1),\n",
       " (u'I', 8),\n",
       " (u'Ishmael', 18),\n",
       " (u\"Ishmael's\", 1),\n",
       " (u\"It's\", 1),\n",
       " (u'Queequeg', 1),\n",
       " (u'So', 1),\n",
       " (u'Some', 1),\n",
       " (u'Well', 1),\n",
       " (u'Yes', 1),\n",
       " (u'a', 4),\n",
       " (u'ago', 1),\n",
       " (u'all', 3),\n",
       " (u'are', 1),\n",
       " (u'as', 1),\n",
       " (u'at', 1),\n",
       " (u'away', 1),\n",
       " (u'awful', 1),\n",
       " (u'backing', 1),\n",
       " (u'be', 2),\n",
       " (u'been', 1),\n",
       " (u'before', 1),\n",
       " (u'buffalo', 1),\n",
       " (u'can', 1),\n",
       " (u'crew', 1),\n",
       " (u'dear', 1),\n",
       " (u'deeper', 1),\n",
       " (u\"didn't\", 1),\n",
       " (u'dive', 1),\n",
       " (u\"don't\", 2),\n",
       " (u'down', 1),\n",
       " (u'explain', 1),\n",
       " (u'fate', 1),\n",
       " (u'for', 2),\n",
       " (u'full-grown', 1),\n",
       " (u'get', 1),\n",
       " (u'go', 4),\n",
       " (u'gone', 2),\n",
       " (u'had', 2),\n",
       " (u'have', 1),\n",
       " (u'hear', 1),\n",
       " (u'heaven', 1),\n",
       " (u'here', 1),\n",
       " (u'hitherto', 1),\n",
       " (u'hope', 1),\n",
       " (u'how', 3),\n",
       " (u'hundredth', 1),\n",
       " (u'hypo', 1),\n",
       " (u'if', 1),\n",
       " (u'in', 1),\n",
       " (u'infallibly', 1),\n",
       " (u'inquire', 1),\n",
       " (u'is', 1),\n",
       " (u'it', 1),\n",
       " (u'land', 1),\n",
       " (u'last', 1),\n",
       " (u'lay', 1),\n",
       " (u'left', 1),\n",
       " (u'long', 1),\n",
       " (u'magnanimous', 1),\n",
       " (u'may', 1),\n",
       " (u'me', 2),\n",
       " (u'mere', 1),\n",
       " (u'mind', 1),\n",
       " (u'muttered', 1),\n",
       " (u'my', 2),\n",
       " (u'myself', 2),\n",
       " (u'name', 1),\n",
       " (u'never', 1),\n",
       " (u'night', 1),\n",
       " (u'now', 2),\n",
       " (u'oarsman', 1),\n",
       " (u'of', 5),\n",
       " (u'on', 2),\n",
       " (u'one', 1),\n",
       " (u'out', 1),\n",
       " (u'pieces', 1),\n",
       " (u'precisely', 1),\n",
       " (u'price', 1),\n",
       " (u'read', 1),\n",
       " (u'rest', 1),\n",
       " (u'robe', 1),\n",
       " (u'said', 2),\n",
       " (u'say', 2),\n",
       " (u'shaking', 1),\n",
       " (u'should', 1),\n",
       " (u'shouts', 1),\n",
       " (u'silver', 1),\n",
       " (u'speak', 1),\n",
       " (u'suppose', 1),\n",
       " (u'sure', 1),\n",
       " (u'surrenderest', 1),\n",
       " (u'teeth-gnashing', 1),\n",
       " (u'than', 1),\n",
       " (u'that', 4),\n",
       " (u'the', 9),\n",
       " (u'then', 1),\n",
       " (u'there', 1),\n",
       " (u'these', 1),\n",
       " (u'this', 1),\n",
       " (u'thou', 1),\n",
       " (u'three', 1),\n",
       " (u'thy', 1),\n",
       " (u'thyself', 1),\n",
       " (u'to', 8),\n",
       " (u'unlettered', 1),\n",
       " (u'up', 1),\n",
       " (u'veritable', 1),\n",
       " (u'vessel', 1),\n",
       " (u'was', 1),\n",
       " (u'whale', 1),\n",
       " (u'whalemen', 1),\n",
       " (u'wherever', 1),\n",
       " (u'which', 1),\n",
       " (u'who', 1),\n",
       " (u'why', 1),\n",
       " (u'with', 1),\n",
       " (u'witness', 1),\n",
       " (u'would', 1),\n",
       " (u'ye', 2),\n",
       " (u'years', 1),\n",
       " (u'you', 7),\n",
       " (u'your', 1)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting data based upon the Key\n",
    "IshmWC.sortByKey(ascending=True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18, u'Ishmael'),\n",
       " (9, u'the'),\n",
       " (8, u'to'),\n",
       " (8, u'I'),\n",
       " (7, u'you'),\n",
       " (5, u'of'),\n",
       " (4, u'that'),\n",
       " (4, u'go'),\n",
       " (4, u'a'),\n",
       " (3, u'how')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to sort by Value do a swap between key & value and then sort\n",
    "IshmWC.map(lambda (x,y): (y,x)).sortByKey().top(10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply this to the whole file:\n",
    "1. read in the file\n",
    "2. use flatMap to split each line into words based upon the regex pattern\n",
    "3. remove splits with no length (filter)\n",
    "4. use map to assign a value 1 to each key (word)\n",
    "5. use reduceByKey to produce a tally(word count) for each word\n",
    "6. save this output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = sc.textFile(infile)\n",
    "wc = f.flatMap(lambda x: re.split(pattern1,x)).filter(lambda x: len(x)>0).map(lambda x: (x, 1)).reduceByKey(add)\n",
    "wc.saveAsTextFile(\"data/wc_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This results in 21130 unique words\n"
     ]
    }
   ],
   "source": [
    "print \"This results in {0} unique words\".format(wc.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To find the most common words use this swap trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13762, u'the'),\n",
       " (6523, u'of'),\n",
       " (6023, u'and'),\n",
       " (4550, u'a'),\n",
       " (4523, u'to'),\n",
       " (3910, u'in'),\n",
       " (2912, u'that'),\n",
       " (2470, u'his'),\n",
       " (2137, u'it'),\n",
       " (1972, u'I'),\n",
       " (1704, u'is'),\n",
       " (1662, u'with'),\n",
       " (1629, u'was'),\n",
       " (1614, u'as'),\n",
       " (1565, u'he'),\n",
       " (1442, u'all'),\n",
       " (1409, u'for'),\n",
       " (1269, u'this'),\n",
       " (1231, u'at'),\n",
       " (1133, u'by'),\n",
       " (1107, u'but'),\n",
       " (1102, u'not'),\n",
       " (1058, u'from'),\n",
       " (1056, u'him'),\n",
       " (1027, u'be'),\n",
       " (1007, u'on'),\n",
       " (917, u'so'),\n",
       " (872, u'one'),\n",
       " (834, u'you'),\n",
       " (767, u'had')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.map(lambda (x,y): (y,x)).sortByKey().top(30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing the Monte Carlo Pi estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "#define the slices as 2\n",
    "slices = 2\n",
    "n = 100000*slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(_):\n",
    "    x = random()*2-1\n",
    "    y = random()*2 -1\n",
    "    return 1 if x**2 + y**2 < 1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.14582\n"
     ]
    }
   ],
   "source": [
    "count = sc.parallelize(xrange(1,n+1),slices).map(f).reduce(add)\n",
    "print \"Pi is roughly {0}\".format((4.0 *count/float(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans in python example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_digits: 10, \t n_samples 1797, \t n_features 64\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "digits = load_digits()\n",
    "data = scale(digits.data)\n",
    "\n",
    "n_samples, n_features = data.shape\n",
    "n_digits = len(np.unique(digits.target))\n",
    "labels = digits.target\n",
    "\n",
    "sample_size = 300\n",
    "\n",
    "print(\"n_digits: %d, \\t n_samples %d, \\t n_features %d\"\n",
    "      % (n_digits, n_samples, n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________\n",
      "init    time  inertia    homo   compl  v-meas     ARI AMI  silhouette\n"
     ]
    }
   ],
   "source": [
    "print(79 * '_')\n",
    "print('% 9s' % 'init'\n",
    "      '    time  inertia    homo   compl  v-meas     ARI AMI  silhouette')\n",
    "\n",
    "\n",
    "def bench_k_means(estimator, name, data):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('% 9s   %.2fs    %i   %.3f   %.3f   %.3f   %.3f   %.3f    %.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=sample_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means++   0.84s    69432   0.602   0.650   0.625   0.465   0.598    0.146\n",
      "   random   0.64s    69694   0.669   0.710   0.689   0.553   0.666    0.147\n",
      "PCA-based   0.05s    71820   0.673   0.715   0.693   0.567   0.670    0.150\n",
      "_______________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10),\n",
    "              name=\"k-means++\", data=data)\n",
    "\n",
    "bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10),\n",
    "              name=\"random\", data=data)\n",
    "\n",
    "# in this case the seeding of the centers is deterministic, hence we run the\n",
    "# kmeans algorithm only once with n_init=1\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\n",
    "              name=\"PCA-based\",\n",
    "              data=data)\n",
    "print(79 * '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAELCAYAAADX3k30AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3CcZ8DxD/siZoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4453745d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Visualize the results on PCA-reduced data\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() + 1, reduced_data[:, 0].max() - 1\n",
    "y_min, y_max = reduced_data[:, 1].min() + 1, reduced_data[:, 1].max() - 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "pl.figure(1)\n",
    "pl.clf()\n",
    "pl.imshow(Z, interpolation='nearest',\n",
    "          extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "          cmap=pl.cm.Paired,\n",
    "          aspect='auto', origin='lower')\n",
    "\n",
    "pl.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "pl.scatter(centroids[:, 0], centroids[:, 1],\n",
    "           marker='x', s=169, linewidths=3,\n",
    "           color='w', zorder=10)\n",
    "pl.title('K-means clustering on the digits dataset (PCA-reduced data)\\n'\n",
    "         'Centroids are marked with white cross')\n",
    "pl.xlim(x_min, x_max)\n",
    "pl.ylim(y_min, y_max)\n",
    "pl.xticks(())\n",
    "pl.yticks(())\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code grabbed from http://ufal.mff.cuni.cz/~straka/courses/npfl102/2014/handout09.pdf\n",
    "from nl t k . t o k e ni z e import w o r d p u n c t t o k e ni z e\n",
    "\n",
    "from pyspark import SparkConf , SparkContext\n",
    "\n",
    "import s y s\n",
    "\n",
    "if len ( s y s . argv ) < 4 :\n",
    "pr int >>s y s . s t d e r r , ”Usage : %s master i n p u t output ” % s y s . argv [ 0 ]\n",
    "e x i t ( 1 )\n",
    "s c = SparkContext ( s y s . argv [ 1 ] , ”Word count ” )\n",
    "f i l e = s c . t e x t F i l e ( s y s . argv [ 2 ] )\n",
    "c oun t s = f i l e . flatMap (lambda x : w o r d p u n c t t o k e ni z e ( x ) ) \\\n",
    ". map(lambda x : ( x , 1 ) ) \\\n",
    ". reduceByKey (lambda x , y : x + y )\n",
    "c oun t s .map(lambda ( x , y ) : ”%s\\t%d” % ( x , y ) ) \\\n",
    ". s a veA sTe x tFile ( s y s . argv [ 3 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
